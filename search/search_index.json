{"config":{"lang":["en"],"separator":"[\\s\\u200b\\u3000\\-\u3001\u3002\uff0c\uff0e\uff1f\uff01\uff1b]+","pipeline":["stemmer"]},"docs":[{"location":"","title":"\u8ba1\u7b97\u673a\u89c6\u89c9","text":"<p>\u4f60\u597d\uff01\u6b22\u8fce\u6765\u5230\u8ba1\u7b97\u673a\u89c6\u89c9\u8bfe\u7a0b\uff01</p> <p>\u672c\u8bfe\u7a0b\u6587\u6863\u9002\u7528\u4e8e 2023-2024 \u51ac\u5b66\u671f\u300a\u8ba1\u7b97\u673a\u89c6\u89c9\u300b\u6f58\u7eb2\u8001\u5e08\u6559\u5b66\u73ed\uff0c\u63d0\u4f9b\u4e00\u4e9b\u8bfe\u7a0b\u4f5c\u4e1a\u7684\u5f15\u5bfc\u3002</p>"},{"location":"#_2","title":"\u7ae0\u8282\u94fe\u63a5","text":"<ul> <li>OpenCV: OpenCV C++ \u6216 opencv-python \u7684\u5b89\u88c5\u548c\u4f7f\u7528</li> <li>HW4: Learning CNN: \u7b2c\u56db\u6b21\u4f5c\u4e1a\u7684\u8bf4\u660e</li> <li>HW5: Learning CNN++: \u7b2c\u4e94\u6b21\u4f5c\u4e1a\u7684\u8bf4\u660e</li> </ul>"},{"location":"hw4/","title":"HW4 Learning CNN","text":""},{"location":"hw4/#hw4-learning-cnn","title":"HW4: Learning CNN","text":""},{"location":"hw4/#_1","title":"\u5b9e\u9a8c\u7b80\u4ecb","text":"<ul> <li>\u6df1\u5ea6\u5b66\u4e60\uff08Deep Learning\uff09\uff1a\u673a\u5668\u5b66\u4e60\u7684\u5206\u652f\uff0c\u662f\u4e00\u79cd\u4ee5\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u4e3a\u67b6\u6784\uff0c\u5bf9\u6570\u636e\u8fdb\u884c\u8868\u5f81\u5b66\u4e60\u7684\u7b97\u6cd5</li> <li>\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08Convolutional Neural Network, CNN\uff09\uff1a\u4e00\u79cd\u524d\u9988\u795e\u7ecf\u7f51\u7edc\uff0c\u5bf9\u4e8e\u5927\u578b\u56fe\u50cf\u5904\u7406\u6709\u51fa\u8272\u8868\u73b0</li> </ul> <p>\u672c\u6b21\u5b9e\u9a8c\u6211\u4eec\u5c06\u5b8c\u6210</p> <ol> <li>LeNet-5 \u7684\u8bad\u7ec3\uff0c\u5e94\u7528\u4e8e MNIST \u6570\u636e\u96c6\u4e0a\u7684\u624b\u5199\u6570\u5b57\u8bc6\u522b\u4efb\u52a1\uff08\u56fe\u50cf\u5206\u7c7b\uff09</li> <li>U-Net \u7684\u7f51\u7edc\u8865\u5168\u4e0e\u6d4b\u8bd5\uff0c\u5e94\u7528\u4e8e Carvana \u6570\u636e\u96c6\u4e0a\u7684\u63a9\u7801 (Mask) \u9884\u6d4b\u4efb\u52a1\uff08\u8bed\u4e49\u5206\u5272\uff09</li> </ol>"},{"location":"hw4/#_2","title":"\u5b9e\u9a8c\u73af\u5883","text":"<p>\u8981\u6c42\u4f7f\u7528 python + pytorch \u5b8c\u6210\u5b9e\u9a8c\uff0c\u63a8\u8350\u4f7f\u7528 miniconda \u6216\u8005 anaconda \u7ba1\u7406\u73af\u5883\u3002</p>"},{"location":"hw4/#conda","title":"\u5b89\u88c5 conda","text":"<p>\u7528 conda \u7ba1\u7406\u73af\u5883\u662f\u56e0\u4e3a\u4f60\u53ef\u80fd\u8981\u7528 python \u5b8c\u6210\u591a\u4e2a\u9879\u76ee\uff0c\u6709\u7684\u9879\u76ee\u7684\u73af\u5883\u4e4b\u95f4\u53ef\u80fd\u5b58\u5728\u96be\u4ee5\u89e3\u51b3\u751a\u81f3\u65e0\u6cd5\u89e3\u51b3\u7684\u51b2\u7a81\u3002conda \u53ef\u4ee5\u5e2e\u52a9\u4f60\u5728\u540c\u4e00\u53f0\u673a\u5b50\u7684\u540c\u4e00\u4e2a\u8d26\u6237\u4e0b\u521b\u5efa\u548c\u7ba1\u7406\u591a\u4e2a python \u73af\u5883\uff0c\u5404\u4e2a\u73af\u5883\u76f8\u4e92\u72ec\u7acb\uff0c\u4e0d\u4f1a\u76f8\u4e92\u5f71\u54cd\uff1b\u800c\u4e14\u6bcf\u4e2a\u73af\u5883\u5c01\u88c5\u5728\u4e00\u4e2a\u6587\u4ef6\u5939\u4e2d\uff0c\u514b\u9686\u3001\u79fb\u9664\u90fd\u5f88\u65b9\u4fbf\u3002</p> <p>Anaconda \u5b8c\u5168\u5305\u542b\u4e86 miniconda\uff0c\u9884\u88c5\u4e86\u8bb8\u591a\u5185\u5bb9\uff0c\u4e5f\u63d0\u4f9b\u56fe\u5f62\u5316\u529f\u80fd\u3002\u76f8\u6bd4\u4e4b\u4e0b miniconda \u6bd4\u8f83\u8f7b\u91cf\u7ea7\uff0c\u53ea\u63d0\u4f9b python \u548c conda \u529f\u80fd\u3002\u76f8\u8f83\u4e4b\u4e0b\u66f4\u63a8\u8350\u4f7f\u7528 miniconda\uff0c\u53ef\u4ee5\u5728 Latest Miniconda installer links by Python version \u4e0b\u8f7d\u5b89\u88c5\u6700\u65b0\u7248\u7684 miniconda\u3002</p> <p>Windows \u7684 conda \u73af\u5883\u914d\u7f6e\u6bd4\u8f83\u9ebb\u70e6\uff0c\u9700\u8981\u5927\u5bb6\u5404\u81ea\u641c\u7d22\u89e3\u51b3\u73af\u5883\u95ee\u9898\uff0c\u53ef\u4ee5\u9002\u5f53\u53c2\u8003\u8fd9\u7bc7\u77e5\u4e4e\u6587\u7ae0\u3002\u53e6\u4e00\u79cd\u89e3\u51b3\u65b9\u6848\u662f\u4f7f\u7528 WSL\uff0c\u5982\u679c\u9700\u8981\u53ef\u4ee5\u53c2\u8003\u672c\u4eba\u5728\u53e6\u4e00\u95e8\u8bfe\u7a0b\u5199\u7684\u6559\u7a0b\u8fdb\u884c\u5b89\u88c5\u3002</p>"},{"location":"hw4/#conda_1","title":"\u65b0\u5efa conda \u73af\u5883","text":"<p>conda \u9ed8\u8ba4\u73af\u5883\u4e3a base\uff0c\u5982\u679c\u505a\u4ec0\u4e48\u90fd\u4f7f\u7528\u8fd9\u4e2a\u73af\u5883\uff0c\u5f88\u5bb9\u6613\u5bfc\u81f4\u73af\u5883\u6df7\u4e71\u3002</p> <p>\u5148\u4e3a\u81ea\u5df1\u8981\u4f7f\u7528\u7684\u73af\u5883\u8d77\u4e00\u4e2a\u540d\u5b57\uff0c\u4f8b\u5982 cv\u3002\u4e0b\u9762\u7684\u547d\u4ee4\u53ef\u4ee5\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a cv\uff0cpython \u7248\u672c\u4e3a 3.10 \u7684\u73af\u5883\u3002</p> <pre><code>conda create cv python=3.10\n</code></pre> <p>conda \u9ed8\u8ba4\u73af\u5883\u4e3a base\uff0c\u9700\u8981\u6fc0\u6d3b\u65b0\u5efa\u7684\u73af\u5883\u624d\u80fd\u4f7f\u7528\u3002</p> <pre><code>conda activate cv\n</code></pre> <p>\u968f\u540e\u5c31\u53ef\u4ee5\u4f7f\u7528 conda \u6216\u8005 pip \u5b89\u88c5\u6240\u9700\u8981\u7684\u5305\u4e86\u3002\u4f8b\u5982 Pytorch\uff0c\u53ef\u4ee5\u901a\u8fc7 PyTorch \u5b98\u7f51\u627e\u5230\u5bf9\u5e94\u7684\u5b89\u88c5\u547d\u4ee4\u3002</p> <p>\u4f8b\u5982\uff0cStable (2.1.2) - Windows - Pip - Python - CPU \u5bf9\u5e94\u7684 Pytorch \u5b89\u88c5\u547d\u4ee4\u4e3a</p> <pre><code>pip3 install torch torchvision torchaudio\n</code></pre>"},{"location":"hw4/#_3","title":"\u5b9e\u9a8c\u57fa\u7840\u77e5\u8bc6\u4ecb\u7ecd","text":""},{"location":"hw4/#_4","title":"\u7f51\u7edc\u6a21\u578b","text":""},{"location":"hw4/#cnn","title":"CNN","text":"<p>CNN \u7531\u4e00\u4e2a\u6216\u591a\u4e2a\u5377\u79ef\u5c42\u548c\u672b\u5c3e\u7684\u5168\u8fde\u63a5\u5c42\uff08\u5bf9\u5e94\u7ecf\u5178\u7684\u795e\u7ecf\u7f51\u7edc\uff09\u7ec4\u6210\uff0c\u540c\u65f6\u4e5f\u5305\u62ec\u5173\u8054\u6743\u91cd\u548c\u6c60\u5316\u5c42\uff08pooling layer\uff09\u3002</p> <p>CNN \u7684\u7279\u70b9\u5305\u62ec</p> <ul> <li>\u5c40\u90e8\u8fde\u63a5\uff1a\u5377\u79ef\u5c42\u7684\u8f93\u51fa\u4e2d\u7684\u5355\u4e2a\u5143\u7d20\u53ea\u53d6\u51b3\u4e8e\u8f93\u5165 feature map \u4e2d\u7684\u5c40\u90e8\u533a\u57df</li> <li>\u6743\u503c\u5171\u4eab\uff1a\u5728\u8f93\u5165 feature map \u7684\u4e0d\u540c\u4f4d\u7f6e\u4f7f\u7528\u76f8\u540c\u7684\u53c2\u6570\uff08\u540c\u4e00\u5377\u79ef\u6838\uff09</li> </ul> <p>\u8fd9\u4e9b\u7279\u70b9\u4f7f\u5176\u53c2\u6570\u91cf\u5927\u5927\u51cf\u5c11\uff0c\u4e14\u5bf9\u5c40\u90e8\u7684\u7a7a\u95f4\u7279\u5f81\u5177\u6709\u5f88\u597d\u7684\u63d0\u53d6\u4f5c\u7528\u3002</p> <p>\u4e0e\u5176\u4ed6\u6df1\u5ea6\u5b66\u4e60\u7ed3\u6784\u76f8\u6bd4\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5728\u56fe\u50cf\u548c\u8bed\u97f3\u8bc6\u522b\u65b9\u9762\u80fd\u591f\u7ed9\u51fa\u66f4\u597d\u7684\u7ed3\u679c\u3002\u8fd9\u4e00\u6a21\u578b\u4e5f\u53ef\u4ee5\u4f7f\u7528\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u8fdb\u884c\u8bad\u7ec3\uff0c\u76f8\u6bd4\u8f83\u5176\u4ed6\u6df1\u5ea6\u3001\u524d\u9988\u795e\u7ecf\u7f51\u7edc\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u9700\u8981\u8003\u91cf\u7684\u53c2\u6570\u66f4\u5c11\uff0c\u4f7f\u4e4b\u6210\u4e3a\u4e00\u79cd\u9887\u5177\u5438\u5f15\u529b\u7684\u6df1\u5ea6\u5b66\u4e60\u7ed3\u6784\u3002</p>"},{"location":"hw4/#lenet-5","title":"LeNet-5","text":"<p>LeNet-5 \u662f\u4e00\u4e2a\u7b80\u5355\u7684\u7ecf\u5178 CNN\uff0c\u53ef\u4ee5\u79f0\u4e4b\u4e3a CNN \u4e2d\u7684 \"Hello World\"\u3002\u4e0b\u56fe\u663e\u793a\u4e86\u5176\u7ed3\u6784\uff1a\u8f93\u5165\u7684\u4e8c\u7ef4\u56fe\u50cf\uff0c\u5148\u7ecf\u8fc7\u4e24\u6b21\u5377\u79ef\u5c42\u5230\u6c60\u5316\u5c42\uff0c\u518d\u7ecf\u8fc7\u5168\u8fde\u63a5\u5c42\uff0c\u6700\u540e\u8f93\u51fa\u6bcf\u79cd\u5206\u7c7b\u9884\u6d4b\u5f97\u5230\u7684\u6982\u7387\u3002</p> <p>\u6709\u5173\u4e8e\u5176\u66f4\u8be6\u7ec6\u7684\u7ed3\u6784\u53ef\u4ee5\u5728 LeNet \u539f\u8bba\u6587 Gradient-based learning applied to document recognition \u4e2d\u627e\u5230\u3002</p>"},{"location":"hw4/#u-net","title":"U-Net","text":"<p>U-Net \u662f\u4e00\u4e2a\u7ecf\u5178\u7684\u8bed\u4e49\u5206\u5272\u5168\u5377\u79ef\u7f51\u7edc\uff0c\u6700\u521d\u5e94\u7528\u4e8e\u533b\u7597\u56fe\u50cf\u7684\u5206\u5272\u4efb\u52a1\u3002\u5176\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u53ef\u4ee5\u770b\u5230 U-Net \u6709\u4e00\u4e2a\u5bf9\u79f0\u7684\u7ed3\u6784\uff0c\u5de6\u8fb9\u662f\u4e00\u4e2a\u5178\u578b\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u53f3\u8fb9\u662f\u4e00\u4e2a\u5bf9\u79f0\u7684\u4e0a\u91c7\u6837\u7f51\u7edc\uff0c\u53ef\u4ee5\u5c06\u5de6\u8fb9\u7684\u7279\u5f81\u56fe\u6062\u590d\u5230\u539f\u56fe\u5927\u5c0f\u3002</p> <p>\u66f4\u591a\u8be6\u7ec6\u5185\u5bb9\u53ef\u4ee5\u53c2\u8003 U-Net \u539f\u8bba\u6587 U-Net: Convolutional Networks for Biomedical Image Segmentation\u3002</p>"},{"location":"hw4/#_5","title":"\u6570\u636e\u96c6","text":""},{"location":"hw4/#mnist","title":"MNIST \u624b\u5199\u6570\u5b57\u6570\u636e\u96c6","text":"<p>MNIST \u6570\u636e\u96c6 (Mixed National Institute of Standards and Technology database) \u662f\u7f8e\u56fd\u56fd\u5bb6\u6807\u51c6\u4e0e\u6280\u672f\u7814\u7a76\u9662\u6536\u96c6\u6574\u7406\u7684\u5927\u578b\u624b\u5199\u6570\u5b57\u6570\u636e\u5e93\uff0c\u5305\u542b 60,000 \u4e2a\u793a\u4f8b\u7684\u8bad\u7ec3\u96c6\u4ee5\u53ca 10,000 \u4e2a\u793a\u4f8b\u7684\u6d4b\u8bd5\u96c6\u3002</p> <p>\u4e00\u822c\u7ed9\u51fa\u7684 MNIST \u6570\u636e\u96c6\u4e0b\u8f7d\u94fe\u63a5\u4e3a http://yann.lecun.com/exdb/mnist/index.html\uff0c\u7136\u800c\u76ee\u524d\u9700\u8981\u767b\u5f55\u9a8c\u8bc1\u3002\u5efa\u8bae\u4f7f\u7528 4.1.1 \u4e2d torchvision.datasets \u7684\u65b9\u6cd5\u51c6\u5907\u8be5\u6570\u636e\u96c6\u3002 </p>"},{"location":"hw4/#carvana","title":"Carvana \u6570\u636e\u96c6","text":"<p>Carvana \u6570\u636e\u96c6 \u662f kaggle \u4e0a\u7684\u4e00\u4e2a\u8bed\u4e49\u5206\u5272\u7ade\u8d5b\u6570\u636e\u96c6\uff0c\u76ee\u6807\u662f\u5b9e\u73b0\u5bf9\u6c7d\u8f66\u7684\u5206\u5272\u3002</p> <p>\u6839\u636e Carvana \u6570\u636e\u96c6\u7684\u5212\u5206\uff0c\u5176\u8bad\u7ec3\u96c6\u5305\u542b 5088 \u5f20\u6c7d\u8f66\u56fe\u7247 (.jpg) \u548c\u5bf9\u5e94\u7684\u63a9\u7801 (mask, .gif)\uff0c\u63a9\u7801\u53ef\u4ee5\u8ba4\u4e3a\u662f 0-1 \u7684\uff0c\u8868\u793a\u56fe\u7247\u4e0a\u6bcf\u4e2a\u50cf\u7d20\u662f\u5426\u5c5e\u4e8e\u6c7d\u8f66\u3002\u56e0\u6b64\u8fd9\u4e2a\u95ee\u9898\u53ef\u4ee5\u5904\u7406\u6210\u9010\u50cf\u7d20\u7684\u4e8c\u5206\u7c7b\u95ee\u9898\u3002</p> <p>\u4e0d\u8981\u6c42\u4e0b\u8f7d\u8be5\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\uff0c\u5c06\u63d0\u4f9b\u5df2\u5728\u8bad\u7ec3\u96c6\u4e0a\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u3002</p>"},{"location":"hw4/#_6","title":"\u5b9e\u9a8c\u6b65\u9aa4","text":""},{"location":"hw4/#lenet-5_1","title":"LeNet-5 \u8bad\u7ec3","text":""},{"location":"hw4/#_7","title":"\u6570\u636e\u51c6\u5907","text":"<p>\u5efa\u8bae\u5229\u7528 <code>torchvision</code> \u63d0\u4f9b\u7684 <code>torchvision.datasets</code> \u65b9\u6cd5\u5bfc\u5165\u6570\u636e\uff0c<code>torchvision.datasets</code> \u6240\u63d0\u4f9b\u7684\u63a5\u53e3\u5341\u5206\u65b9\u4fbf\uff0c\u4e4b\u540e\u4f60\u53ef\u4ee5\u7528 <code>torch.utils.data.DataLoader</code> \u7ed9\u4f60\u7684\u6a21\u578b\u52a0\u8f7d\u6570\u636e\u3002</p> <p>\u5e78\u8fd0\u7684\u662f\uff0c\u672c\u6b21\u5b9e\u9a8c\u9700\u8981\u7528\u5230\u7684 <code>MNIST</code> \u6570\u636e\u96c6\u53ef\u7528 <code>torchvision.datasets</code> \u5bfc\u5165\uff0c\u4e0b\u9762\u5bf9\u4e00\u4e9b\u4f60\u53ef\u80fd\u4f1a\u7528\u5230\u7684\u53c2\u6570\u7b80\u5355\u52a0\u4ee5\u8bf4\u660e</p> <p>\u8bf7\u5728\u6e05\u695a\u53c2\u6570\u542b\u4e49\u540e\u8c03\u7528\u5b83\u4eec</p> <pre><code># MNIST\ntorchvision.datasets.MNIST(root, train=True, transform=None, target_transform=None, download=False)\n</code></pre> <p>\u4e00\u4e9b\u91cd\u8981\u7684\u53c2\u6570\u8bf4\u660e\uff1a</p> <ul> <li><code>root</code>\uff1a\u6570\u636e\u96c6\u6839\u76ee\u5f55\uff0c\u5728 MNIST \u4e2d\u662f <code>processed/training.pt</code> \u548c <code>processed/test.pt</code> \u7684\u4e3b\u76ee\u5f55</li> <li><code>train</code>\uff1a<code>True</code> \u4ee3\u8868\u8bad\u7ec3\u96c6\uff0c<code>False</code> \u4ee3\u8868\u6d4b\u8bd5\u96c6</li> <li><code>transform</code> \u548c <code>target_transform</code>\uff1a\u5206\u522b\u662f\u5bf9\u56fe\u50cf\u548c label \u7684\u8f6c\u6362\u64cd\u4f5c</li> <li><code>download</code>\uff1a\u82e5\u4e3a <code>True</code> \u5219\u4e0b\u8f7d\u6570\u636e\u96c6\u5e76\u653e\u5230 <code>root</code> \u6240\u6307\u5b9a\u7684\u76ee\u5f55\u4e2d\uff0c\u5426\u5219\u76f4\u63a5\u5c1d\u8bd5\u4ece <code>root</code> \u76ee\u5f55\u4e2d\u8bfb\u53d6</li> </ul> <p>\u4f60\u53ef\u4ee5\u5728\u8fd9\u91cc\u83b7\u53d6\u66f4\u52a0\u8be6\u7ec6\u7684\u8bf4\u660e</p>"},{"location":"hw4/#_8","title":"\u6a21\u578b\u7f16\u5199","text":""},{"location":"hw4/#_9","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p><code>PyTorch</code> \u63d0\u4f9b\u4e86\u8bb8\u591a\u79cd\u5b9a\u4e49\u6a21\u578b\u7684\u65b9\u5f0f\uff0c\u6700\u5e38\u7528\u7684\u4e00\u79cd\u662f\u5c06\u7f51\u7edc\u7ed3\u6784\u4ee5\u7c7b\u4fdd\u5b58\uff0c\u4f60\u5e94\u5f53\u9996\u5148\u7ee7\u627f torch.nn.Module\uff0c\u5e76\u5b9e\u73b0\u6b63\u5411\u4f20\u64ad\u7684 <code>forward</code> \u51fd\u6570\uff0c(\u4e3a\u4ec0\u4e48\u4e0d\u7528\u5b9a\u4e49\u53cd\u5411\u4f20\u64ad\u51fd\u6570\u5462\uff1f\u56e0\u4e3a\u4f60\u7ee7\u627f\u7684 <code>nn.Module</code> \u5c31\u662f\u5e72\u8fd9\u4e2a\u4e8b\u60c5\u7684)\u3002</p> <p>\u4e0b\u9762\u4e3a\u7f51\u7edc\u7ed3\u6784\u7684\u4e00\u4e2a sample\uff08\u4f46\u663e\u7136\u8fd9\u6837\u7684\u7f51\u7edc\u5e76\u4e0d\u80fd\u7528\u4e8e\u672c\u6b21 Lab\uff09\uff0c\u672c\u6b21\u5b9e\u9a8c\u4e2d\u4f60\u9700\u8981\u81ea\u5b9a\u4e49\u4f60\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u4ee5\u5b8c\u6210\u6211\u4eec\u7684\u5206\u7c7b\u4efb\u52a1\uff1a</p> <pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__() # \u5229\u7528\u53c2\u6570\u521d\u59cb\u5316\u7236\u7c7b\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre> <p>\u5f53\u7136\uff0c\u4f60\u9700\u8981\u5b9e\u4f8b\u5316\u4f60\u7684\u6a21\u578b\uff0c\u53ef\u4ee5\u76f4\u63a5\u5bf9\u6a21\u578b\u6253\u5370\u4ee5\u67e5\u770b\u7ed3\u6784</p> <pre><code>model = Model()\nprint(model)\n</code></pre> <p>\u7f51\u7edc\u7ed3\u6784\u7f16\u5199\u4e2d\u4e00\u4e2a\u5f88\u5927\u7684\u96be\u70b9\u5728\u4e8e\u6bcf\u4e00\u6b65\u7684 tensor shape \u9700\u8981\u5339\u914d\uff0c\u8bf7\u4ed4\u7ec6\u68c0\u67e5\u4f60\u7684\u4ee3\u7801\u6765\u786e\u4fdd\u6b64\u90e8\u5206\u7684\u6b63\u786e\u6027\u3002</p>"},{"location":"hw4/#_10","title":"\u635f\u5931\u51fd\u6570","text":"<p>\u5e38\u89c1\u7684\u635f\u5931\u51fd\u6570\u90fd\u88ab\u5b9a\u4e49\u5728\u4e86 <code>torch.nn</code>\u4e2d\uff0c\u4f60\u53ef\u4ee5\u5728\u8bad\u7ec3\u8fc7\u7a0b\u5f00\u59cb\u524d\u5c06\u5176\u5b9e\u4f8b\u5316\uff0c\u5e76\u5728\u8bad\u7ec3\u65f6\u8c03\u7528\uff0c\u4f8b\u5982\uff1a</p> <pre><code>criterion = torch.nn.CrossEntropyLoss()\n</code></pre>"},{"location":"hw4/#_11","title":"\u6b63\u5411\u4f20\u64ad","text":"<p>\u6b63\u5411\u4f20\u64ad\u662f\u6307\u5bf9\u795e\u7ecf\u7f51\u7edc\u6cbf\u7740\u4ece\u8f93\u5165\u5c42\u5230\u8f93\u51fa\u5c42\u7684\u987a\u5e8f\uff0c\u4f9d\u6b21\u8ba1\u7b97\u5e76\u5b58\u50a8\u6a21\u578b\u7684\u4e2d\u95f4\u53d8\u91cf\uff08\u5305\u62ec\u8f93\u51fa\uff09\u3002 \u6b63\u5411\u4f20\u64ad\u7684\u8fc7\u7a0b\u5728 <code>forward</code>\u4e2d\u5b9a\u4e49\uff0c\u5bf9\u4e8e\u6a21\u578b\u5b9e\u4f8b\uff0c\u53ef\u4ee5\u76f4\u63a5\u5229\u7528\u8f93\u5165\u8f93\u51fa\u5f97\u5230\u6a21\u578b\u9884\u6d4b\u7684\u7ed3\u679c\u3002</p> <pre><code>y_pred = model(x)\n</code></pre>"},{"location":"hw4/#_12","title":"\u53cd\u5411\u4f20\u64ad","text":"<p>\u53cd\u5411\u4f20\u64ad\uff08Backpropagation\uff0cBP\uff09\u662f\u201c\u8bef\u5dee\u53cd\u5411\u4f20\u64ad\u201d\u7684\u7b80\u79f0\uff0c\u662f\u4e00\u79cd\u4e0e\u6700\u4f18\u5316\u65b9\u6cd5\uff08\u5982\u68af\u5ea6\u4e0b\u964d\u6cd5\uff09\u7ed3\u5408\u4f7f\u7528\u7684\uff0c\u7528\u6765\u8bad\u7ec3\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u7684\u5e38\u89c1\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5bf9\u7f51\u7edc\u4e2d\u6240\u6709\u6743\u91cd\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u7684\u68af\u5ea6\u3002\u8fd9\u4e2a\u68af\u5ea6\u4f1a\u53cd\u9988\u7ed9\u6700\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u6765\u66f4\u65b0\u6743\u503c\u4ee5\u6700\u5c0f\u5316\u635f\u5931\u51fd\u6570\u3002</p> <p>\u5728\u8ba1\u7b97\u8fc7\u6a21\u578b\u7684loss\u4e4b\u540e\uff0c\u53ef\u4ee5\u5229\u7528 <code>loss.backward()</code> \u8ba1\u7b97\u53cd\u5411\u4f20\u64ad\u7684\u68af\u5ea6\uff0c\u68af\u5ea6\u4f1a\u88ab\u76f4\u63a5\u50a8\u5b58\u5728 <code>requires_grad=True</code> \u7684\u8282\u70b9\u4e2d\uff0c\u4e0d\u8fc7\u6b64\u65f6\u8282\u70b9\u7684\u6743\u91cd\u6682\u65f6\u4e0d\u4f1a\u66f4\u65b0\uff0c\u56e0\u6b64\u53ef\u4ee5\u505a\u5230\u68af\u5ea6\u7684\u7d2f\u52a0\u3002</p>"},{"location":"hw4/#_13","title":"\u4f18\u5316\u5668","text":"<p>\u5e38\u7528\u7684\u4f18\u5316\u5668\u90fd\u88ab\u5b9a\u4e49\u5728\u4e86 <code>torch.optim</code> \u4e2d\uff0c\u4e3a\u4e86\u4f7f\u7528\u4f18\u5316\u5668\uff0c\u4f60\u9700\u8981\u6784\u5efa\u4e00\u4e2a optimizer \u5bf9\u8c61\u3002\u8fd9\u4e2a\u5bf9\u8c61\u80fd\u591f\u4fdd\u6301\u5f53\u524d\u53c2\u6570\u72b6\u6001\u5e76\u57fa\u4e8e\u8ba1\u7b97\u5f97\u5230\u7684\u68af\u5ea6\u8fdb\u884c\u53c2\u6570\u66f4\u65b0\u3002\u4f60\u9700\u8981\u7ed9\u5b83\u4e00\u4e2a\u5305\u542b\u4e86\u9700\u8981\u4f18\u5316\u7684\u53c2\u6570\uff08\u5fc5\u987b\u90fd\u662f Variable \u5bf9\u8c61\uff09\u7684iterable\u3002\u7136\u540e\uff0c\u4f60\u53ef\u4ee5\u8bbe\u7f6eoptimizer\u7684\u53c2\u6570\u9009\u9879\uff0c\u6bd4\u5982\u5b66\u4e60\u7387\uff0c\u6743\u91cd\u8870\u51cf\uff0c\u4f8b\u5982\uff1a</p> <pre><code>optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\noptimizer = optim.Adam([var1, var2], lr=0.0001)\n</code></pre> <p>\u6240\u6709\u7684 optimizer \u90fd\u5b9e\u73b0\u4e86 step() \u65b9\u6cd5\uff0c\u8fd9\u4e2a\u65b9\u6cd5\u4f1a\u66f4\u65b0\u6240\u6709\u7684\u53c2\u6570\u3002\u6216\u8bb8\u4f60\u4f1a\u5728\u53cd\u5411\u4f20\u64ad\u540e\u7528\u5230\u5b83\u3002</p> <pre><code>optimizer.step()\n</code></pre> <p>\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5728\u53cd\u5411\u4f20\u64ad\u524d\uff0c\u5982\u679c\u4f60\u4e0d\u5e0c\u671b\u68af\u5ea6\u7d2f\u52a0\uff0c\u8bf7\u4f7f\u7528\u4e0b\u9762\u7684\u4ee3\u7801\u5c06\u68af\u5ea6\u6e05\u96f6\u3002</p> <pre><code>optimizer.zero_grad()\n</code></pre>"},{"location":"hw4/#_14","title":"\u8bad\u7ec3\u8fc7\u7a0b","text":"<p>\u524d\u6587\u4e2d\u5df2\u7ecf\u5b9a\u4e49\u4e86\u7f51\u7edc\u7ed3\u6784\u3001\u635f\u5931\u51fd\u6570\u3001\u4f18\u5316\u5668\uff0c\u81f3\u6b64\uff0c\u4e00\u4e2a\u8f83\u4e3a\u5b8c\u6574\u7684\u8bad\u7ec3\u8fc7\u7a0b\u5982\u4e0b\uff0c\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u4f60\u7684\u8bad\u7ec3\u8fc7\u7a0b\u8981\u4e0d\u65ad\u4ece <code>DataLoader</code> \u4e2d\u53d6\u51fa\u6570\u636e\u3002</p> <pre><code>criterion = torch.nn.MSELoss(reduction='sum')\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-8, momentum=0.9)\nfor t in range(30000):\n    # Forward pass: Compute predicted y by passing x to the model\n    y_pred = model(x)\n\n    # Compute and print loss\n    loss = criterion(y_pred, y)\n\n    # Zero gradients, perform a backward pass, and update the weights.\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n</code></pre>"},{"location":"hw4/#_15","title":"\u6d4b\u8bd5\u8fc7\u7a0b","text":"<p>\u4e00\u822c\u6765\u8bf4\uff0c\u795e\u7ecf\u7f51\u7edc\u4f1a\u591a\u6b21\u5728\u8bad\u7ec3\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u4e00\u6b21\u8bad\u7ec3\u79f0\u4e4b\u4e3a\u4e00\u4e2a epoch\u3002\u6bcf\u4e2a epoch \u7ed3\u675f\u540e\uff0c\u6211\u4eec\u4f1a\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u4ee5\u8bc4\u4f30\u6a21\u578b\u7684\u6027\u80fd\u3002\u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u4e0d\u9700\u8981\u8ba1\u7b97\u68af\u5ea6\u4e5f\u4e0d\u53ef\u4ee5\u8ba1\u7b97\u68af\u5ea6\uff08\u601d\u8003\u4e3a\u4ec0\u4e48\uff09\uff0c\u6b64\u65f6\u53ef\u4ee5\u4f7f\u7528 <code>torch.no_grad</code> \u6765\u5b9e\u73b0\u8fd9\u4e00\u70b9\u3002</p> <pre><code>with torch.no_grad():\n    y_pred = model(x_test)\n    loss = criterion(y_pred, y_test)\n</code></pre>"},{"location":"hw4/#tips","title":"Tips","text":"<ul> <li><code>nn.functional.relu</code>  \uff08\u7b80\u8bb0\u4e3a <code>F.relu</code> \uff09\u548c <code>nn.ReLU</code> \u7565\u6709\u4e0d\u540c\uff0c\u533a\u522b\u5728\u4e8e\u524d\u8005\u4f5c\u4e3a\u4e00\u4e2a\u51fd\u6570\u8c03\u7528\uff0c\u800c\u540e\u8005\u4f5c\u4e3a\u4e00\u4e2a\u5c42\u7ed3\u6784\uff0c\u5fc5\u987b\u6dfb\u52a0\u5230 <code>nn.Module</code> \u5bb9\u5668\u4e2d\u624d\u80fd\u4f7f\u7528\uff0c\u4e24\u8005\u5b9e\u73b0\u7684\u529f\u80fd\u4e00\u6837\uff0c\u5728 <code>PyTorch</code> \u4e2d\uff0c<code>nn.X</code> \u90fd\u6709\u5bf9\u5e94\u7684\u51fd\u6570\u7248\u672c <code>F.X</code>\u3002</li> <li>\u9664\u4e86\u5229\u7528\u7ee7\u627f <code>nn.Module</code> \u6765\u5efa\u7acb\u7f51\u7edc\uff0c\u4e0d\u63a8\u8350\u4f46\u53ef\u4ee5\u4f7f\u7528 <code>nn.ModuleList</code>, <code>nn.ModuleDict</code>\uff0c\u63a8\u8350\u4f7f\u7528 <code>nn.Sequential</code>\u76f4\u63a5\u5b9a\u4e49\u6a21\u578b</li> <li> <p>\u4f60\u53ef\u4ee5\u5b9a\u4e49\u5982\u4e0b\u7684 <code>device</code> \u53d8\u91cf\uff0c\u4ee5\u4fbf\u4f60\u7684\u6a21\u578b\u5728\u6ca1\u6709 GPU \u73af\u5883\u4e0b\u4e5f\u53ef\u4ee5\u6d4b\u8bd5\uff1a</p> <pre><code>device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = Model().to(device)\nsome_data = some_data.to(device)\n</code></pre> </li> <li> <p>\u4f60\u4e0d\u5fc5\u4e25\u683c\u6309\u7167\u539f\u7248 LeNet-5 \u7684\u7f51\u7edc\u7ed3\u6784\u6765\u5b9e\u73b0\uff0c\u5305\u62ec\u8d85\u53c2\u6570\u3001\u4f18\u5316\u5668\u7684\u9009\u62e9\u4e0d\u9650\uff0c\u4f46\u662f\u4f60\u9700\u8981\u4fdd\u8bc1\u4f60\u7684\u7f51\u7edc\u7ed3\u6784\u662f\u5408\u7406\u7684\uff0c\u4e14\u80fd\u591f\u5b8c\u6210\u6211\u4eec\u7684\u5206\u7c7b\u4efb\u52a1\uff0c\u6700\u7ec8\u7684\u6d4b\u8bd5\u96c6\u51c6\u786e\u7387\u9700\u8981\u8fbe\u5230 98% \u4ee5\u4e0a\u3002\uff08\u5b9e\u9645\u4e0a\u539f\u7248 LeNet \u53ef\u4ee5\u8f7b\u677e\u8fbe\u5230\u8fd9\u4e2a\u51c6\u786e\u7387\uff0c\u4f7f\u7528\u66f4\u52a0\u73b0\u4ee3\u7684\u7ed3\u6784\u548c\u4f18\u5316\u5668\uff0c\u4f60\u53ef\u4ee5\u8fbe\u5230\u66f4\u9ad8\u7684\u51c6\u786e\u7387\uff09</p> </li> <li>\u4e0d\u5fc5\u8fc7\u5ea6\u5173\u6ce8\u51c6\u786e\u7387\u548c loss\uff0c\u8bc4\u5206\u5c06\u66f4\u5173\u6ce8\u6709\u610f\u4e49\u7684\u63a2\u7d22\u8fc7\u7a0b\u8bb0\u5f55\u800c\u4e0d\u662f\u6027\u80fd\u6570\u503c\u3002</li> </ul>"},{"location":"hw4/#u-net_1","title":"U-Net \u8865\u5168\u4e0e\u6d4b\u8bd5","text":""},{"location":"hw4/#u-net_2","title":"U-Net \u7ed3\u6784\u89e3\u8bfb","text":"<p>\u5728 U-Net \u539f\u8bba\u6587 U-Net: Convolutional Networks for Biomedical Image Segmentation \u4e2d\uff1a</p> <ul> <li>\u5de6\u4fa7\u5411\u4e0b\u7684\u7ed3\u6784\u88ab\u79f0\u4e3a Contracting Path\uff0c\u7531\u901a\u9053\u6570\u4e0d\u65ad\u589e\u52a0\u7684\u5377\u79ef\u5c42\u548c\u6c60\u5316\u5c42\u7ec4\u6210</li> <li>\u53f3\u4fa7\u5411\u4e0a\u7684\u7ed3\u6784\u88ab\u79f0\u4e3a Expanding Path\uff0c\u7531\u901a\u9053\u6570\u4e0d\u65ad\u51cf\u5c11\u7684\u5377\u79ef\u5c42\u548c\u4e0a\u91c7\u6837\u5c42\uff08\u53cd\u5377\u79ef\u5c42\uff09\u7ec4\u6210</li> <li>\u5728 Expanding Path \u4e2d\uff0c\u6bcf\u6b21\u4e0a\u91c7\u6837\u5c42\u90fd\u4f1a\u5c06 Contracting Path \u4e2d\u5bf9\u5e94\u7684\u7279\u5f81\u56fe\u4e0e\u81ea\u8eab\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u62fc\u63a5\uff0c\u8fd9\u6837\u53ef\u4ee5\u4fdd\u8bc1 Expanding Path \u4e2d\u7684\u6bcf\u4e00\u5c42\u90fd\u80fd\u591f\u5229\u7528 Contracting Path \u4e2d\u7684\u4fe1\u606f</li> </ul>"},{"location":"hw4/#_16","title":"\u7f51\u7edc\u8865\u5168","text":"<p>\u8981\u6c42\u5b8c\u6210 unet.py \u4e2d\u5168\u90e8\u7684 <code>TODO</code>\uff0c\u4f7f\u5f97\u6240\u63d0\u4f9b\u7684\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u53ef\u4ee5\u88ab\u6b63\u786e\u52a0\u8f7d\u3002</p> <p>\u6574\u4f53\u4e0a\u6765\u770b\uff0c\u9700\u8981\u5b8c\u6210\u7684\u5185\u5bb9\u4e3a <code>UNet</code> \u7c7b <code>__init__</code> \u4e2d\u90e8\u5206\u5377\u79ef\u5c42\u7684\u5b9a\u4e49\uff0c\u4ee5\u53ca <code>forward</code> \u51fd\u6570\u4e2d\u7684 Contracting Path \u548c Expanding Path \u7684\u524d\u9012\u3002\u4e0d\u8fc7\uff0c<code>UNet</code> \u7c7b <code>__init__</code> \u8865\u5168\u8fc7\u7a0b\u4e2d\u8fd8\u9700\u8981\u5b9e\u73b0 <code>CropAndConcat</code> \u7c7b\u3002</p> <p>\u4ee5\u4e0b\u4ee3\u7801\u53ea\u662f\u5c55\u793a\u4e00\u4e2a\u6846\u67b6\u4fbf\u4e8e\u7eb5\u89c2\u5168\u90e8\u5185\u5bb9\uff0c\u8bf7\u70b9\u51fb\u6587\u6863\u4e2d unet.py \u6587\u5b57\u6240\u5bf9\u5e94\u7684\u94fe\u63a5\u4e0b\u8f7d\u5305\u542b\u66f4\u591a\u63d0\u793a\u7684\u6a21\u677f\u8fdb\u884c\u7f51\u7edc\u8865\u5168</p> <pre><code>class UNet(nn.Module):\n    def __init__(self, in_channels: int, out_channels: int):\n        ...\n\n        # TODO: Double convolution layers for the contracting path.\n        ...\n\n        # Down sampling layers for the contracting path\n\n        # TODO: The two convolution layers at the lowest resolution (the bottom of the U).\n\n        # Up sampling layers for the expansive path.\n\n        # TODO: Double convolution layers for the expansive path.\n        ...\n\n        # Crop and concatenate layers for the expansive path.\n        # TODO: Implement class CropAndConcat starting from line 6\n        ...\n\n        # TODO: Final 1*1 convolution layer to produce the output\n        ...\n\n\n    def forward(self, x: torch.Tensor):\n        \"\"\"\n        :param x: input image\n        \"\"\"\n        # TODO: Contracting path\n        ...\n\n        # Two 3*3 convolutional layers at the bottom of the U-Net\n        x = self.middle_conv(x)\n\n        # TODO: Expansive path\n        ...\n</code></pre>"},{"location":"hw4/#__init__","title":"<code>__init__</code> \u4e2d\u7684\u5377\u79ef\u5c42\u5b9a\u4e49","text":"<ul> <li>\u901a\u9053\u6570\u7684\u53d8\u5316\u5df2\u7ecf\u5728\u524d\u9762\u7684\u56fe\u4e2d\u8fdb\u884c\u4e86\u6807\u6ce8\u3002\u548c\u539f\u8bba\u6587\u4e0d\u540c\uff0c\u8bad\u7ec3\u65f6 final_conv \u7684\u8f93\u51fa\u901a\u9053\u6539\u6210\u4e86 1\uff0c\u4f46\u662f\u5728\u901a\u7528\u7684\u7f51\u7edc\u7ed3\u6784\u4e2d\u5c31\u662f <code>out_channels</code></li> <li>down_conv, mid_conv \u548c up_conv \u90fd\u662f\u7531\u4e24\u4e2a\u5377\u79ef\u5c42\u7ec4\u6210\uff0c\u6bcf\u4e2a\u5377\u79ef\u5c42\u90fd\u662f \\(3\\times 3\\) \u7684\u5377\u79ef\u6838\uff0cpadding \u4e3a \\(1\\)\uff0cstride \u4e3a \\(1\\)\u3002\u6bcf\u4e2a\u5377\u79ef\u5c42\u540e\u90fd\u6709\u4e00\u4e2a ReLU \u6fc0\u6d3b\u51fd\u6570\uff0c\u6574\u4f53\u987a\u5e8f\u4e3a Conv2d-Relu-Conv2d-Relu</li> <li>final_conv \u662f\u4e00\u4e2a \\(1\\times 1\\) \u7684\u5377\u79ef\u5c42\uff0cpadding \u4e3a \\(0\\)\uff0cstride \u4e3a \\(1\\)\uff0c\u6ca1\u6709\u6fc0\u6d3b\u51fd\u6570</li> </ul> <p>\u53ea\u9700\u8981\u5728\u6709 <code>TODO</code> \u7684\u5730\u65b9\u586b\u5199\uff0c\u5728 <code>nn.Sequential</code> \u7684\u62ec\u53f7\u4e2d\u6b63\u5e38\u586b\u5199 <code>nn.Conv2d</code>, <code>nn.ReLU</code> \u5373\u53ef\u3002\u4e0d\u8981\u81ea\u5b9a\u4e49\u7f51\u7edc\u7c7b\uff0c\u907f\u514d\u6a21\u578b\u56e0\u4e3a\u5c42\u547d\u540d\u4e0d\u4e00\u81f4\u800c\u52a0\u8f7d\u5931\u8d25\u3002</p>"},{"location":"hw4/#cropandconcat","title":"<code>CropAndConcat</code> \u7c7b\u7684\u5b9e\u73b0","text":"<p><code>CropAndConcat</code> \u7c7b\u7684\u4f5c\u7528\u662f\u5c06 Contracting Path \u4e2d\u7684\u7279\u5f81\u56fe\u4e0e Expanding Path \u4e2d\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u62fc\u63a5\uff0c\u4ee5\u4fdd\u8bc1 Expanding Path \u4e2d\u7684\u6bcf\u4e00\u5c42\u90fd\u80fd\u591f\u5229\u7528 Contracting Path \u4e2d\u7684\u4fe1\u606f\u3002</p> <ul> <li>\u9700\u8981\u4f7f\u7528 <code>torchvision.transforms.functional.center_crop(...)</code> \u5bf9 Contracting Path \u4e2d\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u88c1\u526a\uff0c\u4ee5\u4fdd\u8bc1\u5c3a\u5bf8\u4e00\u81f4\u80fd\u591f\u6210\u529f\u62fc\u63a5</li> <li><code>b, c, h, w</code> \u56db\u4e2a\u53d8\u91cf\u5e76\u4e0d\u662f\u90fd\u4f1a\u7528\u5230\uff0c\u4f46\u662f\u4f60\u9700\u8981\u77e5\u9053\u5b83\u4eec\u7684\u542b\u4e49\uff0c\u4fbf\u4e8e\u6b63\u786e\u4f7f\u7528 <code>center_crop(...)</code><ul> <li><code>b</code>\uff1abatch size</li> <li><code>c</code>\uff1achannel</li> <li><code>h</code>\uff1aheight</li> <li><code>w</code>\uff1awidth</li> </ul> </li> <li>\u8bf7\u81ea\u884c\u641c\u7d22\u67e5\u627e <code>torch.cat()</code> \u7684\u7528\u6cd5\uff0c\u4f7f\u5f97\u80fd\u7b26\u5408\u539f\u8bba\u6587\u4e2d\u7684\u62fc\u63a5\u65b9\u5f0f</li> <li>\u4e0e\u56fe\u4e2d\u76f8\u53cd\uff0c\u5b9e\u9645\u62fc\u63a5\u7684\u987a\u5e8f\u4e3a Expanding Path \u4e2d\u7684 feature map \u5728\u5de6\uff0cContracting Path \u4e2d\u7684feature map \u5728\u53f3</li> <li>\u8fd9\u91cc\u7684\u4ee3\u7801\u91cf\u975e\u5e38\u5c0f\uff0c\u57fa\u672c\u4e24\u4e09\u884c\uff0c\u4e0d\u8981\u5199\u590d\u6742\u4e86</li> </ul> <pre><code>class CropAndConcat(nn.Module):\n    \"\"\"\n    ### Crop and Concatenate the feature map\n\n    Crop the feature map from the contracting path to the size of the current feature map\n    \"\"\"\n    def forward(self, x: torch.Tensor, contracting_x: torch.Tensor):\n        \"\"\"\n        :param x: current feature map in the expansive path\n        :param contracting_x: corresponding feature map from the contracting path\n        \"\"\"\n\n        b, c, h, w = x.shape\n\n        # TODO: Concatenate the feature maps\n        # use torchvision.transforms.functional.center_crop(...)\n        x = torch.cat(\n            # ...\n        )\n\n        return x\n</code></pre>"},{"location":"hw4/#unet-forward","title":"<code>UNet</code> \u7c7b\u4e2d <code>forward</code> \u7684\u5b9e\u73b0","text":"<p>\u524d\u9762\u5982\u679c\u90fd\u5b9e\u73b0\u6b63\u786e\uff0c\u8fd9\u91cc\u662f\u6bd4\u8f83\u7b80\u5355\u7684\uff0c\u76f8\u5f53\u4e8e\u5bf9\u7740\u56fe\u8fde\u7ebf\u3002\u6ce8\u610f\u5728 Contracting Path \u4e2d\u4fdd\u7559\u4e2d\u95f4\u7ed3\u679c\uff0c\u5728 Expanding Path \u4e2d Crop and Concat \u65f6\u53ef\u4ee5\u4f7f\u7528\u3002</p>"},{"location":"hw4/#_17","title":"\u6a21\u578b\u52a0\u8f7d\u6d4b\u8bd5","text":"<p>\u63d0\u4f9b\u6a21\u578b\u6587\u4ef6 <code>model.pth</code>\uff0c\u4f60\u53ef\u4ee5\u7528\u4ee5\u4e0b\u7684\u4ee3\u7801\u6d4b\u8bd5\u4f60\u8865\u5168\u7684\u7f51\u7edc\u662f\u5426\u80fd\u6210\u529f\u52a0\u8f7d\u8be5\u6a21\u578b\u3002</p> <pre><code>import argparse\nimport torch\nfrom unet import UNet\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description='Predict masks from input images')\n    parser.add_argument('--model', '-m', default='model.pth',\n                        help='Specify the file in which the model is stored')\n    args = parser.parse_args()\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    print(f'Loading model {args.model}')\n    print(f'Using device {device}')\n\n    model = UNet(in_channels=3, out_channels=1).to(device)\n    state_dict = torch.load(args.model, map_location=device)\n    model.load_state_dict(state_dict)\n\n    print('Model loaded')\n</code></pre> <p>\u4f8b\u5982\uff0c\u5c06\u8be5\u6d4b\u8bd5\u4ee3\u7801\u5199\u5728 <code>try.py</code>\uff0c\u5e76\u5c06\u5176\u548c <code>unet.py</code> \u653e\u5728\u540c\u4e00\u76ee\u5f55\u4e0b\uff0c\u7528 <code>--model</code> \u6307\u5b9a <code>model.pth</code> \u7684\u8def\u5f84\uff0c\u4ee5\u6a21\u578b\u6587\u4ef6\u548c\u4ee3\u7801\u5728\u540c\u4e00\u76ee\u5f55\u4e3a\u4f8b\uff0c\u5219\u53ef\u4ee5\u8fd0\u884c</p> <pre><code>python try.py --model model.pth\n</code></pre> <p>\u5982\u679c\u8f93\u51fa <pre><code>Loading model model.pth\nUsing device cpu\nModel loaded\n</code></pre></p> <p>\u5219\u8bf4\u660e\u4f60\u7684\u7f51\u7edc\u8865\u5168\u6b63\u786e\u3002\u5f53\u7136\uff0c\u7b2c\u4e00\u4e8c\u884c\u7684\u8f93\u51fa\u4e0d\u540c\u60c5\u51b5\u53ef\u80fd\u4e0d\u540c\uff0c\u6211\u4eec\u5173\u6ce8\u7684\u91cd\u5fc3\u5728\u4e8e\u7b2c\u4e09\u884c\u8f93\u51fa \"Model loaded\"\u3002</p>"},{"location":"hw4/#_18","title":"\u5355\u56fe\u63a8\u65ad\u6d4b\u8bd5","text":"<p>\u8981\u6c42\u52a0\u8f7d\u63d0\u4f9b\u7684\u6a21\u578b <code>model.pth</code>\uff0c\u5bf9\u63d0\u4f9b\u7684\u5355\u5f20\u6c7d\u8f66\u56fe\u7247\u7684 mask \u8fdb\u884c\u63a8\u65ad\uff0c\u6709\u5982\u4e0b\u7684\u5173\u952e\u70b9\uff1a</p> <ul> <li>\u4f7f\u7528 <code>Image.open()</code> \u8bfb\u5165\u7684\u5355\u5f20\u56fe\u7247\u9700\u8981\u5229\u7528 <code>torchvision.transforms</code> \u8fdb\u884c\u9002\u5f53\u7684\u9884\u5904\u7406\u3002<ul> <li>Resize \u4e3a 572</li> <li>\u8f6c\u6362\u4e3a Tensor</li> </ul> </li> <li>\u53ef\u80fd\u9700\u8981\u7528\u5230 <code>torch.nn.functional.interpolate</code> \u8fdb\u884c\u63d2\u503c\uff0c\u548c\u56fe\u7247\u5c3a\u5bf8\u5339\u914d</li> <li>\u6a21\u578b\u7684\u8f93\u5165\u8f93\u51fa\u90fd\u5177\u6709 <code>[B, C, H, W]</code> \u7684\u683c\u5f0f</li> <li>\u6a21\u578b\u76f4\u63a5\u4ea7\u751f\u7684\u8f93\u51fa\u662f\u4e00\u4e2a score\u3002\u9996\u5148\u9700\u8981\u7528 sigmoid \u8fdb\u884c\u5904\u7406\uff0c\u7136\u540e\u4f7f\u7528\u4e00\u5b9a\u7684\u9608\u503c\u6765\u5c06\u5176\u8f6c\u6362\u4e3a 0-1 \u7684 mask</li> </ul> <p>\u5728\u8fd9\u91cc\u7b80\u5355\u63d0\u4f9b\u7ed9\u5b9a\u56fe\u7247 <code>img</code>\u3001\u9884\u6d4b\u7684\u63a9\u7801 <code>mask</code> \u548c\u4fdd\u5b58\u56fe\u7247\u540d <code>filename</code> \u800c\u5c06\u56fe\u7247\u548c\u9884\u6d4b\u7684\u63a9\u7801\u4ee5 <code>filename</code> \u4fdd\u5b58\u7684\u4ee3\u7801\uff1a</p> <pre><code>import matplotlib.pyplot as plt\n\ndef plot_img_and_mask(img, mask, filename):\n    classes = mask.max()\n    fig, ax = plt.subplots(1, classes + 1)\n    ax[0].set_title('Input image')\n    ax[0].imshow(img)\n    ax[1].set_title('Mask')\n    ax[1].imshow(mask == 0)\n    plt.savefig(filename)\n    plt.close()\n</code></pre> <p>\u6548\u679c\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p>"},{"location":"hw4/#_19","title":"\u5b9e\u9a8c\u4efb\u52a1\u4e0e\u8981\u6c42","text":"<p>\u4e0d\u5141\u8bb8\u76f4\u63a5\u4f7f\u7528\u5404\u79cd\u6df1\u5ea6\u5b66\u4e60\u5f00\u53d1\u5de5\u5177\u5df2\u8bad\u7ec3\u597d\u7684\u7f51\u7edc\u7ed3\u6784\u4e0e\u53c2\u6570</p> <p>\u53c2\u8003\u6587\u7ae0\u3001\u4ee3\u7801\u9700\u5728\u62a5\u544a\u4e2d\u5217\u51fa\uff0c\u5e76\u4f53\u73b0\u51fa\u4f60\u7684\u7406\u89e3\uff0c\u5426\u5219\u4e00\u7ecf\u67e5\u51fa\u89c6\u4e3a\u6284\u88ad</p> <ol> <li>LeNet-5\uff1a<ol> <li>\u4f7f\u7528 <code>PyTorch</code> \u5b9e\u73b0\u6700\u57fa\u672c\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc LeNet-5\uff0c\u5e76\u5728 MNIST \u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3</li> <li>\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u83b7\u5f97\u8bc6\u522b\u51c6\u786e\u7387\uff0c\u9700\u8981\u8fbe\u5230 98% \u4ee5\u4e0a</li> <li>\u7531\u4e8e LeNet-5 \u592a\u8fc7\u7ecf\u5178\u3001\u53c2\u8003\u8d44\u6599\u8fc7\u591a\uff0c\u4ee3\u7801\u7684\u6e05\u6670\u7a0b\u5ea6\u548c\u9002\u5f53\u7684\u539f\u521b\u6ce8\u91ca\u4e5f\u5c06\u662f\u57fa\u672c\u8bc4\u5206\u9879</li> <li>(bonus) \u5bf9\u8d85\u53c2\u3001\u4f18\u5316\u5668\u3001\u7f51\u7edc\u7ed3\u6784\u7b49\u8fdb\u884c\u6709\u610f\u4e49\u7684\u63a2\u7d22\u5b9e\u9a8c\uff0c\u5c06\u7ed9\u4e88\u9002\u5f53\u7684 bonus\u3002\u4e0d\u9f13\u52b1\u65e0\u610f\u4e49\u7684\u5185\u5377\u5806\u5b9e\u9a8c\uff0c\u8bc4\u5206\u65f6\u5c06\u914c\u60c5\u8003\u8651\u3002</li> </ol> </li> <li>U-Net\uff1a<ol> <li>\u63d0\u4f9b\u7684\u6587\u4ef6\uff1aunet.py\u3001try.py\u3001infer.jpg\uff0cmodel.pth \u53ef\u4ee5\u4ece\u5b66\u5728\u6d59\u5927\u6216\u9489\u9489\u7fa4\u4e0b\u8f7d</li> <li>\u8865\u5168 unet.py \u4e2d\u7684 <code>TODO</code>\uff0c\u4f7f\u5f97\u6240\u63d0\u4f9b\u7684\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u53ef\u4ee5\u88ab\u6b63\u786e\u52a0\u8f7d</li> <li>\u5229\u7528\u6240\u63d0\u4f9b\u7684\u6a21\u578b\uff0c\u63a8\u65ad\u6240\u63d0\u4f9b\u7684\u5355\u5f20\u6c7d\u8f66\u56fe\u7247(infer.jpg)\u7684 mask</li> </ol> </li> <li>\u4f5c\u4e3a\u4e00\u4e2a\u63a2\u7d22\uff0c\u672c\u6b21\u4f5c\u4e1a\u5206\u6570\u6784\u6210\u6309\u5982\u4e0b\u5212\u5206\uff1a<ol> <li>LeNet \u57fa\u672c\u8981\u6c42\uff1a50</li> <li>U-Net \u57fa\u672c\u8981\u6c42\uff1a50</li> <li>LeNet bonus\uff1a5</li> <li>\u603b\u5206\u4e3a\u8be5\u4e09\u90e8\u5206\u4e4b\u548c\uff0c100 \u5206\u5c01\u9876</li> </ol> </li> <li>\u622a\u6b62\u65f6\u95f4\uff1a2024 \u5e74 1 \u6708 2 \u65e5\u4e0a\u5348\uff0c\u8be6\u89c1\u5b66\u5728\u6d59\u5927</li> <li>\u4f60\u9700\u8981\u63d0\u4ea4\uff1a<ol> <li>\u5168\u90e8\u4ee3\u7801</li> <li>\u5b9e\u9a8c\u62a5\u544a\uff0c\u9664\u4e86\u6a21\u677f\u8981\u6c42\u4e4b\u5916\uff0c\u8fd8\u9700\u8981\u5305\u542b\uff1a<ol> <li>\u5bf9\u4e8e LeNet-5\uff0c\u7ed9\u51fa\u6a21\u578b\u7684\u635f\u5931\u66f2\u7ebf\u3001\u8bc6\u522b\u51c6\u786e\u7387\u66f2\u7ebf\u7b49\u56fe\u8868\u3002\u53ef\u4ee5\u5229\u7528 tensorboard \u53ef\u89c6\u5316\u8bad\u7ec3\u8fc7\u7a0b\u5e76\u76f4\u63a5\u5728\u5176\u4e2d\u622a\u56fe\uff0c\u53ef\u4ee5\u53c2\u8003 PyTorch \u7684\u5b98\u65b9\u6559\u7a0b\u5b8c\u6210\u914d\u7f6e\u3002</li> <li>\u5bf9\u4e8e LeNet-5\uff0c\u4f60\u9700\u8981\u5199\u660e\u6d4b\u8bd5\u96c6\u4e0a\u7684\u8bc6\u522b\u6b63\u786e\u7387</li> <li>\u5bf9\u4e8e U-Net\uff0c\u7ed9\u51fa <code>plot_img_and_mask</code> \u51fd\u6570\u751f\u6210\u7684\u56fe\u7247 (infer.jpg \u548c\u6240\u9884\u6d4b\u7684 mask)</li> <li>U-Net \u662f\u539f\u521b\u5b9e\u9a8c\uff0c\u6b22\u8fce\u5728\u62a5\u544a\u611f\u60f3\u90e8\u5206\u63d0\u4f9b\u53cd\u9988</li> </ol> </li> <li>\u4ee3\u7801\u5e94\u5355\u72ec\u6253\u5305\u4e3a\u538b\u7f29\u6587\u4ef6\uff0c\u547d\u540d\u4e3a <code>\u5b66\u53f7-\u59d3\u540d-CVHW4</code> \u7684\u683c\u5f0f\u3002\u5b9e\u9a8c\u62a5\u544a\u5e94\u5f53\u5355\u72ec\u4e0a\u4f20\u9644\u4ef6\uff0c\u4fdd\u8bc1\u53ef\u4ee5\u5728\u7f51\u9875\u76f4\u63a5\u6253\u5f00\u5b9e\u9a8c\u62a5\u544a\u8fdb\u884c\u9884\u89c8\uff0c\u547d\u540d\u4efb\u610f\u3002</li> </ol> </li> </ol> <p>Deadline \u4e4b\u540e\u4ea4\uff1a\u6309 80% \u5206\u6570\u8ba1\u7b97\u6210\u7ee9</p>"},{"location":"hw4/#_20","title":"\u53c2\u8003\u8d44\u6599","text":"<ul> <li>PyTorch \u6846\u67b6</li> <li>PyTorch Lightning \u6846\u67b6</li> <li>MNIST \u6570\u636e\u96c6\uff08\u9700\u9a8c\u8bc1\uff09</li> <li>LeNet \u539f\u8bba\u6587 Gradient-based learning applied to document recognition</li> <li>PyTorch \u6269\u5c55</li> <li>Dive into Deep Learning</li> <li>Carvana \u6570\u636e\u96c6</li> <li>U-Net \u539f\u8bba\u6587 U-Net: Convolutional Networks for Biomedical Image Segmentation</li> </ul>"},{"location":"hw4/#acknowledgement","title":"Acknowledgement","text":"<p>\u975e\u5e38\u611f\u8c22 chiakicage \u4e3a\u53e6\u4e00\u95e8\u9ad8\u8d28\u91cf\u8bfe\u7a0b\u7f16\u5199\u7684\u5b9e\u9a8c\u6587\u6863\uff0c\u8ba9\u6211\u80fd\u591f\u5728\u6b64\u57fa\u7840\u4e0a\u8fdb\u884c\u4fee\u6539\uff0c\u8ba9\u8be5\u5b9e\u9a8c\u5f97\u4ee5\u5728\u77ed\u671f\u5185\u53d1\u5e03\u3002</p>"},{"location":"hw5/","title":"HW5 Learning CNN++","text":""},{"location":"hw5/#hw5-learning-cnn","title":"HW5: Learning CNN++","text":""},{"location":"hw5/#_1","title":"\u5b9e\u9a8c\u7b80\u4ecb","text":"<ul> <li>Kaggle\uff1a\u8c37\u6b4c\u65d7\u4e0b\u7684\u6570\u636e\u79d1\u5b66\u7ade\u8d5b\u5e73\u53f0\uff0c\u6709\u5f00\u653e\u7684\u6bd4\u8d5b\u3001\u6570\u636e\u96c6\u3001\u6a21\u578b\u3001\u8ba8\u8bba\u7b49\uff0c\u7528\u6237\u53ef\u4ee5\u53c2\u4e0e\u6bd4\u8d5b\u6253\u699c\u3001\u83b7\u53d6\u6570\u636e\u96c6\u7ec3\u4e60\u3001\u5206\u4eab\u81ea\u5df1\u6a21\u578b\u4e0e\u7ecf\u9a8c</li> <li>Jupyter Notebook\uff1a\u975e\u8425\u5229\u7ec4\u7ec7 Jupyter \u7684\u4ea7\u54c1\uff0c\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u57fa\u4e8e Web \u7684\u4ea4\u4e92\u5f0f\u8ba1\u7b97\u73af\u5883\uff0c\u5141\u8bb8\u7528\u6237\u5728 .ipynb \u6587\u6863\u4e2d\u5206\u4eab markdown \u6587\u672c\u3001\u4ee3\u7801\u4ee5\u53ca\u4ee3\u7801\u6267\u884c\u7ed3\u679c</li> </ul> <p>\u5728\u4e0a\u6b21\u5b9e\u9a8c\u5b66\u4e60 CNN \u7684\u57fa\u7840\u4e0a\uff0c\u672c\u6b21\u5b9e\u9a8c\u6211\u4eec\u5c06\u4f7f\u7528 CNN \u5b8c\u6210 Kaggle \u516c\u5f00\u6570\u636e\u96c6 Pokemon Image Dataset \u4e0a\u7684\u7cbe\u7075\u5b9d\u53ef\u68a6\u7c7b\u578b\u9884\u6d4b\u4efb\u52a1\u3002</p>"},{"location":"hw5/#_2","title":"\u5b9e\u9a8c\u73af\u5883","text":"<p>\u8981\u6c42\u4f7f\u7528 python + pytorch \u5b8c\u6210\u5b9e\u9a8c\uff0c\u4e0d\u5141\u8bb8\u4f7f\u7528\u53c2\u8003\u4ed3\u5e93\u4e2d\u7684 tensorflow \u4ee3\u7801\u3002</p>"},{"location":"hw5/#_3","title":"\u5b9e\u9a8c\u57fa\u7840\u77e5\u8bc6\u4ecb\u7ecd","text":""},{"location":"hw5/#cnn","title":"CNN \u7ed3\u6784\u7b80\u8ff0","text":"<p>\u4e0a\u6b21\u5b9e\u9a8c\u5b66\u4e60\u7684 LeNet \u5960\u5b9a\u4e86\u4e00\u79cd CNN \u7684\u7ecf\u5178\u7ed3\u6784\uff1a\u5377\u79ef\u5c42\u4e0e\u6c60\u5316\u5c42\u4ea4\u66ff\u51fa\u73b0\uff0c\u540e\u63a5\u4e00\u7cfb\u5217\u5168\u8fde\u63a5\u5c42\uff0c\u6700\u7ec8\u5f97\u5230\u8f93\u51fa\u3002\u8fd9\u79cd\u7ecf\u5178\u7ed3\u6784\u4e5f\u5728 AlexNet \u4e2d\u5f97\u5230\u6cbf\u7528\uff0c\u5e76\u4e14\u5728 2012 \u5e74\u4e00\u9e23\u60ca\u4eba\u3002\u4f60\u5c06\u4f1a\u6ce8\u610f\u5230\uff0c\u672c\u6b21\u5b9e\u9a8c\u7684\u53c2\u8003\u6848\u4f8b\u4e5f\u4f1a\u7528\u5230\u8fd9\u79cd\u7ed3\u6784\u3002</p> <p>\u540e\u6765\uff0cCNN \u7684\u7ed3\u6784\u53c8\u6709\u5982\u4e0b\u7684\u4e00\u4e9b\u53d1\u5c55\uff1a</p> <ul> <li>\u7531\u4e8e\u5168\u8fde\u63a5\u5c42\u53ef\u4ee5\u770b\u6210\u4e00\u79cd\u5377\u79ef\u7684\u89c2\u70b9\u51fa\u73b0\uff0c\u5168\u5377\u79ef (full convolution) \u7f51\u7edc\u51fa\u73b0</li> <li>\u968f\u7740 CNN \u53ef\u89c6\u5316\u7814\u7a76\u7684\u8fdb\u5c55\uff0cCNN \u4e2d\u95f4\u5c42\u7684\u8f93\u51fa\u88ab\u8ba4\u4e3a\u662f\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u63d0\u53d6</li> <li>\u4e0a\u6b21\u5b9e\u9a8c\u6240\u63d0\u5230\u7684 U-Net\uff0c\u5219\u662f\u5c06\u4e0d\u540c\u5c3a\u5ea6\u7684\u4fe1\u606f\u901a\u8fc7\u4e00\u79cd skip \u4e0e concat \u7684\u65b9\u5f0f\u7ec4\u5408\u5229\u7528\uff0c\u5728\u56fe\u50cf\u5206\u5272\u4e0a\u8fbe\u5230\u4e86\u5f88\u597d\u7684\u6548\u679c</li> <li>\u968f\u7740 VGG\u3001ResNet \u8fd9\u4e9b\u5728\u5f53\u65f6\u88ab\u8ba4\u4e3a\u53c2\u6570\u91cf\u8db3\u591f\u5927\u7684\u6a21\u578b\u51fa\u73b0\uff0c\u5728\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u53c2\u6570\u57fa\u7840\u4e0a\u66f4\u6539\u7f51\u7edc\u7ed3\u6784\u8fdb\u884c\u5fae\u8c03 (finetune) \u7684\u6280\u672f\u4e5f\u9010\u6e10\u6210\u719f\u8d77\u6765</li> <li>......</li> </ul> <p>\u968f\u7740 Transformer \u4ece\u673a\u5668\u7ffb\u8bd1\u9886\u57df\u5f00\u59cb\u6380\u8d77\u7684\u4e00\u573a\u53d8\u9769\uff0cVision Transformer (ViT) \u628a Attention \u4e5f\u5e26\u5230\u4e86\u89c6\u89c9\u9886\u57df\u3002\u5728\u672c\u5b66\u671f\u8bfe\u7a0b\u4e2d\u65b0\u589e\u5185\u5bb9\u4e2d\u4e5f\u5305\u542b Attention\uff0c\u4f60\u4e5f\u53ef\u4ee5\u5c1d\u8bd5\u501f\u9274 Attention \u5728\u89c6\u89c9\u9886\u57df\u7684\u5e94\u7528\uff0c\u5728\u4f60\u7684\u6a21\u578b\u4e2d\u52a0\u5165 Attention\u3002</p>"},{"location":"hw5/#_4","title":"\u6570\u636e\u96c6\u7b80\u4ecb","text":"<p>Pokemon Image Dataset \u662f Kaggle \u4e0a\u7684\u4e00\u4e2a\u516c\u5f00\u6570\u636e\u96c6\uff0c\u5305\u542b\u4e86 1 \u4ee3\u5230 7 \u4ee3\u6240\u6709\u7684\u5b9d\u53ef\u68a6 (Pokemon)\uff0c\u6bcf\u79cd\u5b9d\u53ef\u68a6\u7684\u7c7b\u578b\u4fe1\u606f\uff08Type1 &amp; Type2\uff09\u90fd\u88ab\u5305\u542b\u5728 <code>pokemon.csv</code> \u4e2d\u3002</p> <p>\u7531\u4e8e Type2 \u5bf9\u4e8e\u67d0\u4e9b\u5b9d\u53ef\u68a6\u6765\u8bf4\u662f\u7a7a\u7684\uff0c\u56e0\u6b64\u9700\u8981\u5fc5\u8981\u7684\u6570\u636e\u9884\u5904\u7406\u3002\u4e3a\u4e86\u51cf\u5c11\u5927\u5bb6\u65e0\u5173 CNN \u7684\u5de5\u4f5c\u91cf\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6848\u4f8b\u53ef\u4ee5\u53c2\u8003\u5b66\u4e60\u3002</p>"},{"location":"hw5/#_5","title":"\u6570\u636e\u589e\u5e7f","text":"<p>\u6570\u636e\u589e\u5e7f (data augmentation) \u662f\u5728\u5f53\u524d\u6709\u9650\u7684\u56fe\u50cf\u6570\u636e\u96c6\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u6570\u636e\u91cf\u7684\u4e00\u79cd\u65b9\u6cd5\uff0c\u5e38\u89c1\u7684\u6570\u636e\u589e\u5e7f\u65b9\u6cd5\u662f\u5bf9\u539f\u59cb\u7684\u56fe\u50cf\u8fdb\u884c\u4eff\u5c04\u53d8\u6362\u800c\u6807\u7b7e\u4e0d\u53d8\uff0c\u53e6\u5916\u50cf\u53d6 patch \u4e5f\u662f\u4e00\u79cd\u5e38\u89c1\u7684\u6570\u636e\u589e\u5e7f\u65b9\u5f0f\u3002\u66f4\u591a\u6570\u636e\u589e\u5e7f\u7684\u65b9\u6cd5\u6709\u5f85\u63a2\u7d22\u3002</p> <p>\u53ef\u4ee5\u53c2\u8003 Dive into Deep Learning - Image Augmentation \u5b66\u4e60\u6570\u636e\u589e\u5e7f\u7684\u4f7f\u7528\u3002</p>"},{"location":"hw5/#_6","title":"\u5b9e\u9a8c\u8bbe\u7f6e","text":""},{"location":"hw5/#_7","title":"\u53c2\u8003\u6848\u4f8b","text":"<p>\u7ed9\u51fa\u4e00\u4e2a\u53ef\u53c2\u8003\u7684\u6848\u4f8b pokemon-types\uff0c\u6ce8\u610f\u8be5 github \u4ed3\u5e93\u6ca1\u6709\u7ed9\u51fa LICENSE\uff0c\u9ed8\u8ba4\u4e00\u5207\u6743\u5229\u7531\u4f5c\u8005\u6240\u6709\uff0c\u56e0\u6b64\u5927\u5bb6\u6ce8\u610f\u8fdb\u884c\u501f\u9274\u5b66\u4e60\u3002\u63d0\u4ea4\u7684\u5185\u5bb9\u4e0d\u80fd\u662f .ipynb \u6587\u4ef6\u3002</p> <p>\u53ef\u4ee5\u53c2\u8003\u8be5\u6848\u4f8b\u4e2d\u7684\u6570\u636e\u9884\u5904\u7406\u3001\u8f93\u5165\u8f93\u51fa\u9002\u914d\uff0c\u51cf\u5c11\u4e0e CNN \u65e0\u5173\u7684\u5de5\u4f5c\u91cf\u3002\u8be5\u4ed3\u5e93\u4e2d\u7ed9\u51fa\u4e86\u7528 tensorflow.keras \u5b9e\u73b0\u7684\u4e00\u79cd CNN \u7ed3\u6784\uff0c\u53ef\u4ee5\u4f5c\u4e3a baseline\uff0c\u4f46\u662f\u5fc5\u987b\u81ea\u5df1\u4f7f\u7528 PyTorch \u5b9e\u73b0\u3002</p> <p>\u53e6\u5916 Kaggle \u5e73\u53f0\u4e0a\u7684\u8ba8\u8bba\u4e5f\u6709\u5f88\u591a\u53ef\u4ee5\u53c2\u8003\u5b66\u4e60\u7684\u5185\u5bb9\uff0c\u5927\u5bb6\u53ef\u4ee5\u81ea\u884c\u63a2\u7d22\u3002</p>"},{"location":"hw5/#-","title":"\u8bad\u7ec3\u96c6-\u6d4b\u8bd5\u96c6\u5212\u5206","text":"<p>\u5bf9\u4e8e\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u5212\u5206\uff0c\u4f7f\u7528\u7edf\u4e00\u7684 train.csv \u548c test.csv\uff0c\u5206\u522b\u5305\u542b 687 \u53ea\u548c 122 \u53ea\u5b9d\u53ef\u68a6\u3002</p> <p>\u4e0d\u5141\u8bb8\u4f7f\u7528\u522b\u7684\u8bad\u7ec3\u96c6\u3001\u6d4b\u8bd5\u96c6\u8bbe\u7f6e\uff0c\u4e0d\u5fc5\u5f15\u5165\u4ea4\u53c9\u9a8c\u8bc1\u96c6\u3002</p>"},{"location":"hw5/#_8","title":"\u6d4b\u8bd5\u96c6\u6cc4\u9732","text":"<ul> <li>\u8981\u6c42\u7684\u8bad\u7ec3\u96c6\u542b 687 \u53ea\u5b9d\u53ef\u68a6\uff0c\u6d4b\u8bd5\u96c6\u542b 122 \u53ea\u5b9d\u53ef\u68a6</li> <li>\u6d4b\u8bd5\u96c6\u6cc4\u9732\u6307\u4f7f\u7528\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u5168\u90e8\u6570\u636e\uff08\u5171 809 \u53ea\u5b9d\u53ef\u68a6\uff09\u8fdb\u884c\u8bad\u7ec3</li> <li>\u800c\u6b63\u786e\u7684\u64cd\u4f5c\u662f\u4e0d\u5e94\u8be5\u6cc4\u9732\u6d4b\u8bd5\u96c6\uff0c\u53ea\u6839\u636e\u8bad\u7ec3\u96c6 687 \u53ea\u5b9d\u53ef\u68a6\u8fdb\u884c\u8bad\u7ec3</li> </ul> <p>\u5982\u679c\u6d4b\u8bd5\u96c6\u6cc4\u9732\uff0c\u7406\u8bba\u4e0a\u53ef\u4ee5\u8ba9\u6a21\u578b\u201c\u8bb0\u4f4f\u201d\u6d4b\u8bd5\u96c6\u7684\u6570\u636e\uff0c\u4ece\u800c\u8fbe\u5230\u795e\u4e4e\u5176\u795e\u7684 100% \u6d4b\u8bd5\u51c6\u786e\u7387\uff0c\u800c\u8fd9\u663e\u7136\u662f\u4e0d\u5bf9\u7684\u3002</p>"},{"location":"hw5/#_9","title":"\u5b9e\u9a8c\u4efb\u52a1\u4e0e\u8981\u6c42","text":"<p>\u4e0d\u5141\u8bb8\u76f4\u63a5\u4f7f\u7528\u5404\u79cd\u6df1\u5ea6\u5b66\u4e60\u5f00\u53d1\u5de5\u5177\u5df2\u8bad\u7ec3\u597d\u7684\u7f51\u7edc\u7ed3\u6784\u4e0e\u53c2\u6570</p> <p>\u6269\u5c55\u8981\u6c42\u4e2d\u5141\u8bb8\u5229\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002</p> <p>\u53c2\u8003\u6587\u7ae0\u3001\u4ee3\u7801\u9700\u5728\u62a5\u544a\u4e2d\u5217\u51fa\uff0c\u5e76\u4f53\u73b0\u51fa\u4f60\u7684\u7406\u89e3\uff0c\u5426\u5219\u4e00\u7ecf\u67e5\u51fa\u89c6\u4e3a\u6284\u88ad</p>"},{"location":"hw5/#_10","title":"\u5b9e\u9a8c\u8981\u6c42","text":"<p>\u57fa\u672c\u8981\u6c42\u5305\u62ec\uff1a</p> <ol> <li>\u4f7f\u7528 PyTorch \u81ea\u5df1\u8bbe\u8ba1 CNN\uff0c\u81ea\u5df1\u8bad\u7ec3\u5b8c\u6210 Pokemon Image Dataset \u4e0a\u7684\u7cbe\u7075\u5b9d\u53ef\u68a6\u7c7b\u578b\u9884\u6d4b\u4efb\u52a1 <p>\u53ef\u4ee5\u81ea\u5df1\u8bbe\u8ba1 CNN\uff0c\u53ef\u4ee5\u53c2\u8003\u6848\u4f8b\u4e2d\u7684 CNN\uff0c\u4e5f\u53ef\u4ee5\u4fee\u6539 LeNet \u7b49\u7ed3\u6784\uff0c\u4f46\u662f\u4e0d\u5141\u8bb8\u4f7f\u7528\u9884\u8bad\u7ec3\u53c2\u6570\uff0c\u5fc5\u987b\u4ece\u5934\u8bad\u7ec3</p> </li> <li>\u5e94\u7528\u6570\u636e\u589e\u5e7f\u65b9\u6cd5</li> <li>\u8c03\u6574\u8d85\u53c2\u6570\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u5bf9\u6d4b\u8bd5\u96c6\u4e0a\u7684\u51c6\u786e\u7387\u7b49\u5b9e\u9a8c\u7ed3\u679c\u8fdb\u884c\u6bd4\u8f83\u5206\u6790</li> <li>\u8981\u6c42\u5728\u6d4b\u8bd5\u96c6\u6cc4\u9732\u548c\u4e0d\u6cc4\u9732\u4e24\u79cd\u60c5\u51b5\u4e0b\u8fdb\u884c\u8bad\u7ec3\uff0c\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u5bf9\u6bd4</li> </ol> <p>\u70b9\u51fb\u4e0b\u8f7d\u8981\u6c42\u7684\u8bad\u7ec3\u96c6\u3001\u6d4b\u8bd5\u96c6\u5212\u5206\u914d\u7f6e\uff1atrain.csv \u548c test.csv</p> <p>\u6269\u5c55\u8981\u6c42\u4e3a\u5c1d\u8bd5\u4fee\u6539\u7f51\u7edc\u7ed3\u6784\u751a\u81f3\u91c7\u7528\u65b0\u7684\u67b6\u6784\u5e94\u7528\u4e8e\u8be5\u4efb\u52a1\uff0c\u8fdb\u884c\u5b9e\u9a8c\u4e0e\u6bd4\u8f83\u3002\u5b9e\u9a8c\u57fa\u7840\u77e5\u8bc6\u90e8\u5206\u63d0\u4f9b\u4e86\u4e00\u4e9b\u53ef\u4ee5\u53c2\u8003\u7684\u601d\u8def\u3002</p>"},{"location":"hw5/#_11","title":"\u63d0\u4ea4\u8981\u6c42","text":"<p>\u622a\u6b62\u65f6\u95f4\uff1a2024 \u5e74 1 \u6708 24 \u65e5\u4e0a\u5348\uff0c\u8be6\u89c1\u5b66\u5728\u6d59\u5927</p> <p>\u5927\u5bb6\u7279\u522b\u6ce8\u610f\uff1addl \u4e4b\u540e\u9a6c\u4e0a\u8981\u6279\u6539\u5e76\u63d0\u4ea4\u603b\u6210\u7ee9\uff0c\u6240\u4ee5\u82e5 ddl \u524d\u6ca1\u80fd\u63d0\u4ea4\u8be5\u4f5c\u4e1a\u5c06\u6309\u96f6\u5206\u8ba1\u7b97</p> <p>\u4f60\u9700\u8981\u63d0\u4ea4\uff1a</p> <ol> <li>\u5168\u90e8\u4ee3\u7801</li> <li>\u5b9e\u9a8c\u62a5\u544a\uff0c\u9664\u4e86\u6a21\u677f\u8981\u6c42\u4e4b\u5916\uff0c\u5bf9\u6bd4\u5b9e\u9a8c\u8981\u6c42\u6709\u5206\u6790\u56fe\u8868\uff0c\u5e76\u5199\u660e\u6d4b\u8bd5\u96c6\u4e0a\u7684\u8bc6\u522b\u6b63\u786e\u7387</li> <li>\u4ee3\u7801\u5e94\u5355\u72ec\u6253\u5305\u4e3a\u538b\u7f29\u6587\u4ef6\uff0c\u547d\u540d\u4e3a <code>\u5b66\u53f7-\u59d3\u540d-CVHW5</code> \u7684\u683c\u5f0f\u3002\u5b9e\u9a8c\u62a5\u544a\u5e94\u5f53\u5355\u72ec\u4e0a\u4f20\u9644\u4ef6\uff0c\u4fdd\u8bc1\u53ef\u4ee5\u5728\u7f51\u9875\u76f4\u63a5\u6253\u5f00\u5b9e\u9a8c\u62a5\u544a\u8fdb\u884c\u9884\u89c8\uff0c\u547d\u540d\u4efb\u610f\u3002</li> </ol>"},{"location":"hw5/#_12","title":"\u53c2\u8003\u8d44\u6599","text":"<ul> <li>Pokemon Image Dataset</li> <li>\u53c2\u8003\u6848\u4f8b\u4ed3\u5e93 pokemon-types</li> <li>Dive into Deep Learning - Image Augmentation</li> </ul>"},{"location":"opencv/","title":"OpenCV \u73af\u5883\u914d\u7f6e","text":"<p>\u9875\u9762\u5efa\u8bbe\u4e2d</p>"}]}